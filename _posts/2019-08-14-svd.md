---
layout: single
title:  "Matrix Decompositions: Why and How"
date:   2019-08-14
mathjax: true
---
When we want to talk about matrix factorizations, then we have to start at the beginning: the eigendecomposition and the singular value decomposition. There are so many aspects about these decompositions, I don't think that we will have time to explore them. Here, I just want to talk about the somewhat less known but nevertheless imposrtant optimization problems which these decompositions solve. Let's just take what we need from the vast theory about these decompositions and run with it.

# Eigendecompositions
Let us assume that we have a symmetric, real-valued $m\times m$ matrix $W$. Such a matrix could for example reflect similarities between data points, that is entry $W_{jl}$ denotes the similarity between data points $j$ and $l$.
![Alt Text](https://github.com/Sibylse/ZeroShades/blob/master/assets/images/eigendecomp.png "Eigendecomposition 1")
{% raw %}![alt](/assets/images/eigendecomp.png "eigendecomp 2"){% endraw %}
![alt]({{ site.url }}{{ site.baseurl }}/assets/images/eigendecomp.png "eigendecomp 3")
<figure>
	<a href="https://github.com/Sibylse/ZeroShades/blob/master/assets/images/eigendecomp.png"><img src="https://github.com/Sibylse/ZeroShades/blob/master/assets/images/eigendecomp.png"></a>
</figure>
